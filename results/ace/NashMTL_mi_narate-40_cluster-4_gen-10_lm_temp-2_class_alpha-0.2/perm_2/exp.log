Dump name space
results/ace/NashMTL_mi_narate-40_cluster-4_gen-10_lm_temp-2_class_alpha-0.2/perm_2/options.json
Dump name space
results/ace/NashMTL_mi_narate-40_cluster-4_gen-10_lm_temp-2_class_alpha-0.2/perm_2/options.json
Dump name space
results/ace/NashMTL_mi_narate-40_cluster-4_gen-10_lm_temp-2_class_alpha-0.2/perm_2/options.json
Dump name space
results/ace/NashMTL_mi_narate-40_cluster-4_gen-10_lm_temp-2_class_alpha-0.2/perm_2/options.json
Dump name space
results/ace/NashMTL_mi_narate-40_cluster-4_gen-10_lm_temp-2_class_alpha-0.2/perm_2/options.json
[[188, 199, 184, 194, 189, 190, 178, 186, 197, 0], [200, 180, 173, 198, 177, 0], [191, 187, 195, 171, 174, 179, 0], [196, 181, 182, 202, 185, 176, 170, 192, 0], [201, 183, 193, 172, 175, 0]]
False
train loader and exclude loader:  0
Original len train instances: 265115
train loader and exclude loader:  1
Original len train instances: 264531
train loader and exclude loader:  2
Original len train instances: 263812
train loader and exclude loader:  3
Original len train instances: 262973
train loader and exclude loader:  4
Original len train instances: 262361
Original len dev instances: 54053
Original len test instances: 93949
create basgMTL 4
False True
Epoch   1  Train Loss 1.2314 99.20%
Epoch   1:  Dev 0.4721311628818512
Epoch   1: Test 0.5648148655891418
patience: 0 / 6
Epoch   2  Train Loss 1.1431 99.65%
Epoch   2:  Dev 0.4289405643939972
patience: 1 / 6
Epoch   3  Train Loss 1.1339 99.67%
Epoch   3:  Dev 0.46650126576423645
patience: 2 / 6
Epoch   4  Train Loss 1.1272 99.71%
Epoch   4:  Dev 0.5454545021057129
Epoch   4: Test 0.6754385828971863
patience: 0 / 6
Epoch   5  Train Loss 1.1234 99.75%
Epoch   5:  Dev 0.47411444783210754
patience: 1 / 6
Epoch   6  Train Loss 1.1204 99.78%
Epoch   6:  Dev 0.5114942193031311
patience: 2 / 6
Epoch   7  Train Loss 1.1184 99.80%
Epoch   7:  Dev 0.529032289981842
patience: 3 / 6
Epoch   8  Train Loss 1.1170 99.83%
Epoch   8:  Dev 0.5076452493667603
patience: 4 / 6
Epoch   9  Train Loss 1.1162 99.85%
Epoch   9:  Dev 0.4985673725605011
patience: 5 / 6
Epoch  10  Train Loss 1.1157 99.87%
Epoch  10:  Dev 0.48295459151268005
patience: 6 / 6
setting train exemplar for learned classes
torch.Size([180, 2048])
BEST DEV 0: 0.5454545021057129
BEST TEST 0: 0.6754385828971863
torch.Size([180, 2048])
Epoch   1  Train Loss 5.4730 98.52%
Epoch   1:  Dev 0.5084745287895203
Epoch   1: Test 0.5786408185958862
patience: 0 / 6
Epoch   2  Train Loss 5.3679 99.23%
Epoch   2:  Dev 0.47289159893989563
patience: 1 / 6
Epoch   3  Train Loss 5.3530 99.34%
Epoch   3:  Dev 0.4779299795627594
patience: 2 / 6
Epoch   4  Train Loss 5.3395 99.41%
Epoch   4:  Dev 0.534246563911438
Epoch   4: Test 0.5470383167266846
patience: 0 / 6
Epoch   5  Train Loss 5.3288 99.47%
Epoch   5:  Dev 0.5351170897483826
Epoch   5: Test 0.5328836441040039
patience: 0 / 6
Epoch   6  Train Loss 5.3253 99.52%
Epoch   6:  Dev 0.52173912525177
patience: 1 / 6
Epoch   7  Train Loss 5.3201 99.56%
Epoch   7:  Dev 0.5181347131729126
patience: 2 / 6
Epoch   8  Train Loss 5.3187 99.62%
Epoch   8:  Dev 0.4718416929244995
patience: 3 / 6
Epoch   9  Train Loss 5.3122 99.65%
Epoch   9:  Dev 0.5204081535339355
patience: 4 / 6
Epoch  10  Train Loss 5.3146 99.68%
Epoch  10:  Dev 0.5415860414505005
Epoch  10: Test 0.5821205377578735
patience: 0 / 6
Epoch  11  Train Loss 5.3128 99.73%
Epoch  11:  Dev 0.5165793895721436
patience: 1 / 6
Epoch  12  Train Loss 5.3103 99.73%
Epoch  12:  Dev 0.5308411121368408
patience: 2 / 6
Epoch  13  Train Loss 5.3059 99.75%
Epoch  13:  Dev 0.5238094925880432
patience: 3 / 6
Epoch  14  Train Loss 5.3023 99.78%
Epoch  14:  Dev 0.5035461187362671
patience: 4 / 6
Epoch  15  Train Loss 5.3065 99.80%
Epoch  15:  Dev 0.5285171270370483
patience: 5 / 6
Epoch  16  Train Loss 5.3014 99.82%
Epoch  16:  Dev 0.5341130495071411
patience: 6 / 6
setting train exemplar for learned classes
torch.Size([280, 2048])
BEST DEV 1: 0.5415860414505005
BEST TEST 1: 0.5821205377578735
torch.Size([280, 2048])
Epoch   1  Train Loss 4.9117 97.93%
Epoch   1:  Dev 0.5352112650871277
Epoch   1: Test 0.5879459381103516
patience: 0 / 6
Epoch   2  Train Loss 4.7845 99.50%
Epoch   2:  Dev 0.5496894717216492
Epoch   2: Test 0.5763126015663147
patience: 0 / 6
Epoch   3  Train Loss 4.7743 99.55%
Epoch   3:  Dev 0.5636672377586365
Epoch   3: Test 0.601307213306427
patience: 0 / 6
Epoch   4  Train Loss 4.7643 99.58%
Epoch   4:  Dev 0.545161247253418
patience: 1 / 6
Epoch   5  Train Loss 4.7600 99.60%
Epoch   5:  Dev 0.5365079045295715
patience: 2 / 6
Epoch   6  Train Loss 4.7556 99.65%
Epoch   6:  Dev 0.5690515637397766
Epoch   6: Test 0.5919395089149475
patience: 0 / 6
Epoch   7  Train Loss 4.7514 99.69%
Epoch   7:  Dev 0.5575364828109741
patience: 1 / 6
Epoch   8  Train Loss 4.7450 99.71%
Epoch   8:  Dev 0.5509182214736938
patience: 2 / 6
Epoch   9  Train Loss 4.7472 99.75%
Epoch   9:  Dev 0.5662847757339478
patience: 3 / 6
Epoch  10  Train Loss 4.7439 99.77%
Epoch  10:  Dev 0.5518394708633423
patience: 4 / 6
Epoch  11  Train Loss 4.7438 99.78%
Epoch  11:  Dev 0.5574324131011963
patience: 5 / 6
Epoch  12  Train Loss 4.7414 99.80%
Epoch  12:  Dev 0.5587188601493835
patience: 6 / 6
setting train exemplar for learned classes
torch.Size([400, 2048])
BEST DEV 2: 0.5690515637397766
BEST TEST 2: 0.5919395089149475
torch.Size([400, 2048])
Epoch   1  Train Loss 5.2507 97.36%
Epoch   1:  Dev 0.553398072719574
Epoch   1: Test 0.5662758946418762
patience: 0 / 6
Epoch   2  Train Loss 5.0779 99.43%
Epoch   2:  Dev 0.5551424622535706
Epoch   2: Test 0.5727190971374512
patience: 0 / 6
Epoch   3  Train Loss 5.0627 99.50%
Epoch   3:  Dev 0.5574572086334229
Epoch   3: Test 0.5674499273300171
patience: 0 / 6
Epoch   4  Train Loss 5.0534 99.55%
Epoch   4:  Dev 0.5858855247497559
Epoch   4: Test 0.5779904127120972
patience: 0 / 6
Epoch   5  Train Loss 5.0450 99.62%
Epoch   5:  Dev 0.5797101259231567
patience: 1 / 6
Epoch   6  Train Loss 5.0420 99.66%
Epoch   6:  Dev 0.5710594654083252
patience: 2 / 6
Epoch   7  Train Loss 5.0347 99.68%
Epoch   7:  Dev 0.5835615992546082
patience: 3 / 6
Epoch   8  Train Loss 5.0324 99.72%
Epoch   8:  Dev 0.5654993057250977
patience: 4 / 6
Epoch   9  Train Loss 5.0327 99.75%
Epoch   9:  Dev 0.5768194198608398
patience: 5 / 6
Epoch  10  Train Loss 5.0296 99.77%
Epoch  10:  Dev 0.5922865271568298
Epoch  10: Test 0.5731462836265564
patience: 0 / 6
Epoch  11  Train Loss 5.0258 99.79%
Epoch  11:  Dev 0.5903447866439819
patience: 1 / 6
Epoch  12  Train Loss 5.0255 99.80%
Epoch  12:  Dev 0.5859697461128235
patience: 2 / 6
Epoch  13  Train Loss 5.0280 99.82%
Epoch  13:  Dev 0.5950413346290588
Epoch  13: Test 0.5841785073280334
patience: 0 / 6
Epoch  14  Train Loss 5.0262 99.81%
Epoch  14:  Dev 0.5824175477027893
patience: 1 / 6
Epoch  15  Train Loss 5.0272 99.83%
Epoch  15:  Dev 0.5864453315734863
patience: 2 / 6
Epoch  16  Train Loss 5.0253 99.84%
Epoch  16:  Dev 0.586926281452179
patience: 3 / 6
Epoch  17  Train Loss 5.0230 99.84%
Epoch  17:  Dev 0.5907172560691833
patience: 4 / 6
Epoch  18  Train Loss 5.0214 99.84%
Epoch  18:  Dev 0.5920471549034119
patience: 5 / 6
Epoch  19  Train Loss 5.0242 99.84%
Epoch  19:  Dev 0.586776852607727
patience: 6 / 6
setting train exemplar for learned classes
torch.Size([560, 2048])
BEST DEV 3: 0.5950413346290588
BEST TEST 3: 0.5841785073280334
torch.Size([560, 2048])
Epoch   1  Train Loss 5.2424 97.42%
Epoch   1:  Dev 0.6080508828163147
Epoch   1: Test 0.6342710852622986
patience: 0 / 6
Epoch   2  Train Loss 5.1200 99.41%
Epoch   2:  Dev 0.6171548366546631
Epoch   2: Test 0.6435452699661255
patience: 0 / 6
Epoch   3  Train Loss 5.1106 99.48%
Epoch   3:  Dev 0.6100307106971741
patience: 1 / 6
Epoch   4  Train Loss 5.1035 99.54%
Epoch   4:  Dev 0.6028226017951965
patience: 2 / 6
Epoch   5  Train Loss 5.0980 99.60%
Epoch   5:  Dev 0.6120778322219849
patience: 3 / 6
Epoch   6  Train Loss 5.0919 99.63%
Epoch   6:  Dev 0.6095820069313049
patience: 4 / 6
Epoch   7  Train Loss 5.0913 99.68%
Epoch   7:  Dev 0.6101009845733643
patience: 5 / 6
Epoch   8  Train Loss 5.0880 99.71%
Epoch   8:  Dev 0.6168622970581055
patience: 6 / 6
setting train exemplar for learned classes
torch.Size([660, 2048])
BEST DEV 4: 0.6171548366546631
BEST TEST 4: 0.6435452699661255
