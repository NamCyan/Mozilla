Dump name space
results/ace/FairGrad_KT_woSAM/perm_1/options.json
Dump name space
results/ace/FairGrad_KT_woSAM/perm_1/options.json
Dump name space
results/ace/FairGrad_KT_woSAM/perm_1/options.json
Dump name space
results/ace/FairGrad_KT_woSAM/perm_1/options.json
[[196, 181, 182, 202, 185, 176, 170, 192, 0], [200, 180, 173, 198, 177, 0], [201, 183, 193, 172, 175, 0], [191, 187, 195, 171, 174, 179, 0], [188, 199, 184, 194, 189, 190, 178, 186, 197, 0]]
False
train loader and exclude loader:  0
Original len train instances: 265115
train loader and exclude loader:  1
Original len train instances: 264503
train loader and exclude loader:  2
Original len train instances: 263784
train loader and exclude loader:  3
Original len train instances: 262450
train loader and exclude loader:  4
Original len train instances: 261611
Original len dev instances: 54053
Original len test instances: 93949
create basgMTL 4
False True
Epoch   1  Train Loss 0.1040 98.12%
Epoch   1:  Dev 0.445229709148407
Epoch   1: Test 0.438914030790329
patience: 0 / 6
Epoch   2  Train Loss 0.0247 98.43%
Epoch   2:  Dev 0.4483985900878906
Epoch   2: Test 0.45208847522735596
patience: 0 / 6
Epoch   3  Train Loss 0.0178 98.44%
Epoch   3:  Dev 0.5933014154434204
Epoch   3: Test 0.5
patience: 0 / 6
Epoch   4  Train Loss 0.0127 98.49%
Epoch   4:  Dev 0.5942856669425964
Epoch   4: Test 0.5320512652397156
patience: 0 / 6
Epoch   5  Train Loss 0.0107 98.52%
Epoch   5:  Dev 0.501960813999176
patience: 1 / 6
Epoch   6  Train Loss 0.0085 98.55%
Epoch   6:  Dev 0.6463415026664734
Epoch   6: Test 0.49689435958862305
patience: 0 / 6
Epoch   7  Train Loss 0.0068 98.56%
Epoch   7:  Dev 0.6338797807693481
patience: 1 / 6
Epoch   8  Train Loss 0.0054 98.59%
Epoch   8:  Dev 0.593406617641449
patience: 2 / 6
Epoch   9  Train Loss 0.0052 98.59%
Epoch   9:  Dev 0.6033520102500916
patience: 3 / 6
Epoch  10  Train Loss 0.0042 98.61%
Epoch  10:  Dev 0.6011560559272766
patience: 4 / 6
Epoch  11  Train Loss 0.0034 98.63%
Epoch  11:  Dev 0.6206896901130676
patience: 5 / 6
Epoch  12  Train Loss 0.0036 98.62%
Epoch  12:  Dev 0.5658535957336426
patience: 6 / 6
setting train exemplar for learned classes
torch.Size([160, 2048])
BEST DEV 0: 0.6463415026664734
BEST TEST 0: 0.49689435958862305
torch.Size([160, 2048])
Epoch   1  Train Loss 7.7324 99.37%
Epoch   1:  Dev 0.5833333730697632
Epoch   1: Test 0.5017182230949402
patience: 0 / 6
Epoch   2  Train Loss 9.0946 99.70%
Epoch   2:  Dev 0.594315230846405
Epoch   2: Test 0.5016502141952515
patience: 0 / 6
Epoch   3  Train Loss 9.9311 99.75%
Epoch   3:  Dev 0.6096866130828857
Epoch   3: Test 0.5124555826187134
patience: 0 / 6
Epoch   4  Train Loss 10.2539 99.77%
Epoch   4:  Dev 0.6068601608276367
patience: 1 / 6
Epoch   5  Train Loss 10.7563 99.80%
Epoch   5:  Dev 0.6217617392539978
Epoch   5: Test 0.4982934892177582
patience: 0 / 6
Epoch   6  Train Loss 11.3184 99.82%
Epoch   6:  Dev 0.6189111471176147
patience: 1 / 6
Epoch   7  Train Loss 11.7165 99.83%
Epoch   7:  Dev 0.6074498891830444
patience: 2 / 6
Epoch   8  Train Loss 12.1134 99.85%
Epoch   8:  Dev 0.6039885878562927
patience: 3 / 6
Epoch   9  Train Loss 12.4907 99.87%
Epoch   9:  Dev 0.6067414879798889
patience: 4 / 6
Epoch  10  Train Loss 12.8199 99.88%
Epoch  10:  Dev 0.59620600938797
patience: 5 / 6
Epoch  11  Train Loss 13.4507 99.89%
Epoch  11:  Dev 0.6032609343528748
patience: 6 / 6
setting train exemplar for learned classes
torch.Size([260, 2048])
BEST DEV 1: 0.6217617392539978
BEST TEST 1: 0.4982934892177582
torch.Size([260, 2048])
Epoch   1  Train Loss 9.2867 98.76%
Epoch   1:  Dev 0.6398763060569763
Epoch   1: Test 0.6187291741371155
patience: 0 / 6
Epoch   2  Train Loss 10.9706 99.63%
Epoch   2:  Dev 0.6467818021774292
Epoch   2: Test 0.6321243047714233
patience: 0 / 6
Epoch   3  Train Loss 11.8711 99.66%
Epoch   3:  Dev 0.6623586416244507
Epoch   3: Test 0.6325823068618774
patience: 0 / 6
Epoch   4  Train Loss 12.8296 99.70%
Epoch   4:  Dev 0.6613162159919739
patience: 1 / 6
Epoch   5  Train Loss 13.5472 99.72%
Epoch   5:  Dev 0.6431853175163269
patience: 2 / 6
Epoch   6  Train Loss 14.1238 99.74%
Epoch   6:  Dev 0.6635071039199829
Epoch   6: Test 0.6245734095573425
patience: 0 / 6
Epoch   7  Train Loss 14.6188 99.76%
Epoch   7:  Dev 0.6333333253860474
patience: 1 / 6
Epoch   8  Train Loss 15.1380 99.77%
Epoch   8:  Dev 0.6474359035491943
patience: 2 / 6
Epoch   9  Train Loss 15.7783 99.77%
Epoch   9:  Dev 0.6484848856925964
patience: 3 / 6
Epoch  10  Train Loss 16.3103 99.80%
Epoch  10:  Dev 0.671999990940094
Epoch  10: Test 0.6432953476905823
patience: 0 / 6
Epoch  11  Train Loss 16.5799 99.80%
Epoch  11:  Dev 0.6622735261917114
patience: 1 / 6
Epoch  12  Train Loss 16.8505 99.81%
Epoch  12:  Dev 0.656101405620575
patience: 2 / 6
Epoch  13  Train Loss 17.4669 99.84%
Epoch  13:  Dev 0.6546645760536194
patience: 3 / 6
Epoch  14  Train Loss 17.6346 99.84%
Epoch  14:  Dev 0.6434231400489807
patience: 4 / 6
Epoch  15  Train Loss 18.3588 99.85%
Epoch  15:  Dev 0.6576271057128906
patience: 5 / 6
Epoch  16  Train Loss 18.8997 99.86%
Epoch  16:  Dev 0.6666666865348816
patience: 6 / 6
setting train exemplar for learned classes
torch.Size([360, 2048])
BEST DEV 2: 0.671999990940094
BEST TEST 2: 0.6432953476905823
torch.Size([360, 2048])
Epoch   1  Train Loss 13.0784 99.22%
Epoch   1:  Dev 0.6402266025543213
Epoch   1: Test 0.6457142233848572
patience: 0 / 6
Epoch   2  Train Loss 14.6313 99.73%
Epoch   2:  Dev 0.6495468020439148
Epoch   2: Test 0.656319260597229
patience: 0 / 6
Epoch   3  Train Loss 15.0707 99.75%
Epoch   3:  Dev 0.641509473323822
patience: 1 / 6
Epoch   4  Train Loss 15.5635 99.77%
Epoch   4:  Dev 0.6656805276870728
Epoch   4: Test 0.6413440704345703
patience: 0 / 6
Epoch   5  Train Loss 16.3605 99.79%
Epoch   5:  Dev 0.6568046808242798
patience: 1 / 6
Epoch   6  Train Loss 16.5871 99.80%
Epoch   6:  Dev 0.6508172154426575
patience: 2 / 6
Epoch   7  Train Loss 17.2500 99.81%
Epoch   7:  Dev 0.6497763991355896
patience: 3 / 6
Epoch   8  Train Loss 17.5412 99.83%
Epoch   8:  Dev 0.6491498947143555
patience: 4 / 6
Epoch   9  Train Loss 17.9909 99.83%
Epoch   9:  Dev 0.6604938507080078
patience: 5 / 6
Epoch  10  Train Loss 18.3521 99.84%
Epoch  10:  Dev 0.6645962595939636
patience: 6 / 6
setting train exemplar for learned classes
torch.Size([480, 2048])
BEST DEV 3: 0.6656805276870728
BEST TEST 3: 0.6413440704345703
torch.Size([480, 2048])
Epoch   1  Train Loss 10.7915 98.68%
Epoch   1:  Dev 0.5670419335365295
Epoch   1: Test 0.6258587837219238
patience: 0 / 6
Epoch   2  Train Loss 11.9228 99.74%
Epoch   2:  Dev 0.62153160572052
Epoch   2: Test 0.6301912069320679
patience: 0 / 6
Epoch   3  Train Loss 12.5960 99.77%
Epoch   3:  Dev 0.6276715993881226
Epoch   3: Test 0.6354029178619385
patience: 0 / 6
Epoch   4  Train Loss 13.1802 99.79%
Epoch   4:  Dev 0.6352683305740356
Epoch   4: Test 0.6433750987052917
patience: 0 / 6
Epoch   5  Train Loss 13.8280 99.81%
Epoch   5:  Dev 0.6303161978721619
patience: 1 / 6
Epoch   6  Train Loss 14.5173 99.82%
Epoch   6:  Dev 0.6237514019012451
patience: 2 / 6
Epoch   7  Train Loss 14.9470 99.83%
Epoch   7:  Dev 0.6366704106330872
Epoch   7: Test 0.6413559317588806
patience: 0 / 6
Epoch   8  Train Loss 15.4260 99.83%
Epoch   8:  Dev 0.6482758522033691
Epoch   8: Test 0.643104612827301
patience: 0 / 6
Epoch   9  Train Loss 15.8788 99.85%
Epoch   9:  Dev 0.6458101272583008
patience: 1 / 6
Epoch  10  Train Loss 16.5444 99.86%
Epoch  10:  Dev 0.6183783411979675
patience: 2 / 6
Epoch  11  Train Loss 16.4747 99.86%
Epoch  11:  Dev 0.6137566566467285
patience: 3 / 6
Epoch  12  Train Loss 16.9434 99.87%
Epoch  12:  Dev 0.6355748772621155
patience: 4 / 6
Epoch  13  Train Loss 17.2855 99.87%
Epoch  13:  Dev 0.6287553310394287
patience: 5 / 6
Epoch  14  Train Loss 17.5895 99.88%
Epoch  14:  Dev 0.6162047386169434
patience: 6 / 6
setting train exemplar for learned classes
torch.Size([660, 2048])
BEST DEV 4: 0.6482758522033691
BEST TEST 4: 0.643104612827301
