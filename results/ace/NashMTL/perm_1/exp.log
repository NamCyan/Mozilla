Dump name space
results/ace/NashMTL/perm_1/options.json
Dump name space
results/ace/NashMTL/perm_1/options.json
Dump name space
results/ace/NashMTL/perm_1/options.json
Dump name space
results/ace/NashMTL/perm_1/options.json
[[196, 181, 182, 202, 185, 176, 170, 192, 0], [200, 180, 173, 198, 177, 0], [201, 183, 193, 172, 175, 0], [191, 187, 195, 171, 174, 179, 0], [188, 199, 184, 194, 189, 190, 178, 186, 197, 0]]
False
train loader and exclude loader:  0
Original len train instances: 265115
train loader and exclude loader:  1
Original len train instances: 264503
train loader and exclude loader:  2
Original len train instances: 263784
train loader and exclude loader:  3
Original len train instances: 262450
train loader and exclude loader:  4
Original len train instances: 261611
Original len dev instances: 54053
Original len test instances: 93949
create basgMTL 4
False True
Epoch   1  Train Loss 0.1290 99.21%
Epoch   1:  Dev 0.41584157943725586
Epoch   1: Test 0.4312896430492401
patience: 0 / 6
Epoch   2  Train Loss 0.0371 99.57%
Epoch   2:  Dev 0.43478265404701233
Epoch   2: Test 0.4419134259223938
patience: 0 / 6
Epoch   3  Train Loss 0.0281 99.59%
Epoch   3:  Dev 0.5636363625526428
Epoch   3: Test 0.5093834400177002
patience: 0 / 6
Epoch   4  Train Loss 0.0217 99.65%
Epoch   4:  Dev 0.6010362505912781
Epoch   4: Test 0.5147929191589355
patience: 0 / 6
Epoch   5  Train Loss 0.0177 99.69%
Epoch   5:  Dev 0.47058823704719543
patience: 1 / 6
Epoch   6  Train Loss 0.0139 99.74%
Epoch   6:  Dev 0.5837838053703308
patience: 2 / 6
Epoch   7  Train Loss 0.0120 99.77%
Epoch   7:  Dev 0.6358973979949951
Epoch   7: Test 0.4909090995788574
patience: 0 / 6
Epoch   8  Train Loss 0.0099 99.80%
Epoch   8:  Dev 0.5550239086151123
patience: 1 / 6
Epoch   9  Train Loss 0.0091 99.81%
Epoch   9:  Dev 0.6153846383094788
patience: 2 / 6
Epoch  10  Train Loss 0.0073 99.85%
Epoch  10:  Dev 0.6170212626457214
patience: 3 / 6
Epoch  11  Train Loss 0.0067 99.85%
Epoch  11:  Dev 0.658682644367218
Epoch  11: Test 0.46794870495796204
patience: 0 / 6
Epoch  12  Train Loss 0.0057 99.88%
Epoch  12:  Dev 0.5645932555198669
patience: 1 / 6
Epoch  13  Train Loss 0.0050 99.89%
Epoch  13:  Dev 0.6589595675468445
Epoch  13: Test 0.4833836853504181
patience: 0 / 6
Epoch  14  Train Loss 0.0047 99.91%
Epoch  14:  Dev 0.5201793909072876
patience: 1 / 6
Epoch  15  Train Loss 0.0043 99.91%
Epoch  15:  Dev 0.6181818246841431
patience: 2 / 6
Epoch  16  Train Loss 0.0040 99.92%
Epoch  16:  Dev 0.5975609421730042
patience: 3 / 6
Epoch  17  Train Loss 0.0044 99.91%
Epoch  17:  Dev 0.6010362505912781
patience: 4 / 6
Epoch  18  Train Loss 0.0035 99.94%
Epoch  18:  Dev 0.6242774724960327
patience: 5 / 6
Epoch  19  Train Loss 0.0027 99.95%
Epoch  19:  Dev 0.5833333730697632
patience: 6 / 6
setting train exemplar for learned classes
torch.Size([160, 2048])
BEST DEV 0: 0.6589595675468445
BEST TEST 0: 0.4833836853504181
torch.Size([160, 2048])
Epoch   1  Train Loss 2.8461 98.04%
Epoch   1:  Dev 0.5188285112380981
Epoch   1: Test 0.46327686309814453
patience: 0 / 6
Epoch   2  Train Loss 2.7181 99.40%
Epoch   2:  Dev 0.5778780579566956
Epoch   2: Test 0.4780058264732361
patience: 0 / 6
Epoch   3  Train Loss 2.7032 99.48%
Epoch   3:  Dev 0.5901639461517334
Epoch   3: Test 0.47647058963775635
patience: 0 / 6
Epoch   4  Train Loss 2.6933 99.55%
Epoch   4:  Dev 0.5477178692817688
patience: 1 / 6
Epoch   5  Train Loss 2.6887 99.60%
Epoch   5:  Dev 0.551578938961029
patience: 2 / 6
Epoch   6  Train Loss 2.6884 99.66%
Epoch   6:  Dev 0.6074073910713196
Epoch   6: Test 0.4870130121707916
patience: 0 / 6
Epoch   7  Train Loss 2.6785 99.70%
Epoch   7:  Dev 0.59183669090271
patience: 1 / 6
Epoch   8  Train Loss 2.6767 99.74%
Epoch   8:  Dev 0.5741176605224609
patience: 2 / 6
Epoch   9  Train Loss 2.6696 99.77%
Epoch   9:  Dev 0.5778893828392029
patience: 3 / 6
Epoch  10  Train Loss 2.6772 99.79%
Epoch  10:  Dev 0.5894206166267395
patience: 4 / 6
Epoch  11  Train Loss 2.6712 99.81%
Epoch  11:  Dev 0.5797872543334961
patience: 5 / 6
Epoch  12  Train Loss 2.6668 99.84%
Epoch  12:  Dev 0.5894736647605896
patience: 6 / 6
setting train exemplar for learned classes
torch.Size([260, 2048])
BEST DEV 1: 0.6074073910713196
BEST TEST 1: 0.4870130121707916
torch.Size([260, 2048])
Epoch   1  Train Loss 2.8839 98.00%
Epoch   1:  Dev 0.6049204468727112
Epoch   1: Test 0.5855161547660828
patience: 0 / 6
Epoch   2  Train Loss 2.7936 99.38%
Epoch   2:  Dev 0.63458651304245
Epoch   2: Test 0.6195826530456543
patience: 0 / 6
Epoch   3  Train Loss 2.7842 99.46%
Epoch   3:  Dev 0.6439628601074219
Epoch   3: Test 0.6145161390304565
patience: 0 / 6
Epoch   4  Train Loss 2.7788 99.53%
Epoch   4:  Dev 0.6441718339920044
Epoch   4: Test 0.6281945109367371
patience: 0 / 6
Epoch   5  Train Loss 2.7661 99.59%
Epoch   5:  Dev 0.6452599763870239
Epoch   5: Test 0.618122935295105
patience: 0 / 6
Epoch   6  Train Loss 2.7659 99.63%
Epoch   6:  Dev 0.6438152194023132
patience: 1 / 6
Epoch   7  Train Loss 2.7653 99.66%
Epoch   7:  Dev 0.6288209557533264
patience: 2 / 6
Epoch   8  Train Loss 2.7634 99.69%
Epoch   8:  Dev 0.645550549030304
Epoch   8: Test 0.6203038096427917
patience: 0 / 6
Epoch   9  Train Loss 2.7607 99.71%
Epoch   9:  Dev 0.6471495032310486
Epoch   9: Test 0.6130081415176392
patience: 0 / 6
Epoch  10  Train Loss 2.7566 99.74%
Epoch  10:  Dev 0.659375011920929
Epoch  10: Test 0.6240538358688354
patience: 0 / 6
Epoch  11  Train Loss 2.7589 99.77%
Epoch  11:  Dev 0.6530612111091614
patience: 1 / 6
Epoch  12  Train Loss 2.7535 99.78%
Epoch  12:  Dev 0.664505660533905
Epoch  12: Test 0.6226734519004822
patience: 0 / 6
Epoch  13  Train Loss 2.7574 99.79%
Epoch  13:  Dev 0.6602563858032227
patience: 1 / 6
Epoch  14  Train Loss 2.7553 99.80%
Epoch  14:  Dev 0.6331811547279358
patience: 2 / 6
Epoch  15  Train Loss 2.7518 99.80%
Epoch  15:  Dev 0.6377708911895752
patience: 3 / 6
Epoch  16  Train Loss 2.7526 99.82%
Epoch  16:  Dev 0.6699187159538269
Epoch  16: Test 0.6397188305854797
patience: 0 / 6
Epoch  17  Train Loss 2.7542 99.83%
Epoch  17:  Dev 0.6496815085411072
patience: 1 / 6
Epoch  18  Train Loss 2.7534 99.84%
Epoch  18:  Dev 0.6348733305931091
patience: 2 / 6
Epoch  19  Train Loss 2.7521 99.84%
Epoch  19:  Dev 0.656862735748291
patience: 3 / 6
Epoch  20  Train Loss 2.7534 99.85%
Epoch  20:  Dev 0.6534653306007385
patience: 4 / 6
Epoch  21  Train Loss 2.7498 99.85%
Epoch  21:  Dev 0.6591276526451111
patience: 5 / 6
Epoch  22  Train Loss 2.7502 99.86%
Epoch  22:  Dev 0.6461039185523987
patience: 6 / 6
setting train exemplar for learned classes
torch.Size([360, 2048])
BEST DEV 2: 0.6699187159538269
BEST TEST 2: 0.6397188305854797
torch.Size([360, 2048])
Epoch   1  Train Loss 2.8749 98.79%
Epoch   1:  Dev 0.6283186078071594
Epoch   1: Test 0.6157112717628479
patience: 0 / 6
Epoch   2  Train Loss 2.7951 99.60%
Epoch   2:  Dev 0.6151645183563232
patience: 1 / 6
Epoch   3  Train Loss 2.7828 99.65%
Epoch   3:  Dev 0.6290801167488098
Epoch   3: Test 0.6242038011550903
patience: 0 / 6
Epoch   4  Train Loss 2.7789 99.69%
Epoch   4:  Dev 0.6268656849861145
patience: 1 / 6
Epoch   5  Train Loss 2.7733 99.73%
Epoch   5:  Dev 0.6151604056358337
patience: 2 / 6
Epoch   6  Train Loss 2.7687 99.78%
Epoch   6:  Dev 0.6267280578613281
patience: 3 / 6
Epoch   7  Train Loss 2.7675 99.81%
Epoch   7:  Dev 0.6274510025978088
patience: 4 / 6
Epoch   8  Train Loss 2.7653 99.82%
Epoch   8:  Dev 0.6363636255264282
Epoch   8: Test 0.6244477033615112
patience: 0 / 6
Epoch   9  Train Loss 2.7610 99.85%
Epoch   9:  Dev 0.6301369667053223
patience: 1 / 6
Epoch  10  Train Loss 2.7628 99.86%
Epoch  10:  Dev 0.6246245503425598
patience: 2 / 6
Epoch  11  Train Loss 2.7651 99.86%
Epoch  11:  Dev 0.637499988079071
Epoch  11: Test 0.615963876247406
patience: 0 / 6
Epoch  12  Train Loss 2.7615 99.86%
Epoch  12:  Dev 0.6408669352531433
Epoch  12: Test 0.6248108744621277
patience: 0 / 6
Epoch  13  Train Loss 2.7607 99.88%
Epoch  13:  Dev 0.6454689502716064
Epoch  13: Test 0.6237393617630005
patience: 0 / 6
Epoch  14  Train Loss 2.7626 99.88%
Epoch  14:  Dev 0.6365054249763489
patience: 1 / 6
Epoch  15  Train Loss 2.7618 99.89%
Epoch  15:  Dev 0.6354839205741882
patience: 2 / 6
Epoch  16  Train Loss 2.7617 99.90%
Epoch  16:  Dev 0.629570722579956
patience: 3 / 6
Epoch  17  Train Loss 2.7600 99.90%
Epoch  17:  Dev 0.6403940320014954
patience: 4 / 6
Epoch  18  Train Loss 2.7602 99.91%
Epoch  18:  Dev 0.6336634159088135
patience: 5 / 6
Epoch  19  Train Loss 2.7565 99.91%
Epoch  19:  Dev 0.6357616186141968
patience: 6 / 6
setting train exemplar for learned classes
torch.Size([480, 2048])
BEST DEV 3: 0.6454689502716064
BEST TEST 3: 0.6237393617630005
torch.Size([480, 2048])
Epoch   1  Train Loss 3.0375 98.04%
Epoch   1:  Dev 0.5437881350517273
Epoch   1: Test 0.5964450836181641
patience: 0 / 6
Epoch   2  Train Loss 2.9217 99.67%
Epoch   2:  Dev 0.5653495788574219
Epoch   2: Test 0.6031128764152527
patience: 0 / 6
Epoch   3  Train Loss 2.9066 99.71%
Epoch   3:  Dev 0.5690721869468689
Epoch   3: Test 0.5988103151321411
patience: 0 / 6
Epoch   4  Train Loss 2.8955 99.75%
Epoch   4:  Dev 0.5738045573234558
Epoch   4: Test 0.6082338094711304
patience: 0 / 6
Epoch   5  Train Loss 2.8917 99.80%
Epoch   5:  Dev 0.5865168571472168
Epoch   5: Test 0.593837559223175
patience: 0 / 6
Epoch   6  Train Loss 2.8887 99.83%
Epoch   6:  Dev 0.5758929252624512
patience: 1 / 6
Epoch   7  Train Loss 2.8885 99.85%
Epoch   7:  Dev 0.5736095905303955
patience: 2 / 6
Epoch   8  Train Loss 2.8867 99.86%
Epoch   8:  Dev 0.6062052249908447
Epoch   8: Test 0.5968660712242126
patience: 0 / 6
Epoch   9  Train Loss 2.8834 99.88%
Epoch   9:  Dev 0.594350278377533
patience: 1 / 6
Epoch  10  Train Loss 2.8838 99.89%
Epoch  10:  Dev 0.5746102333068848
patience: 2 / 6
Epoch  11  Train Loss 2.8815 99.89%
Epoch  11:  Dev 0.5743016600608826
patience: 3 / 6
Epoch  12  Train Loss 2.8827 99.90%
Epoch  12:  Dev 0.5954545736312866
patience: 4 / 6
Epoch  13  Train Loss 2.8806 99.90%
Epoch  13:  Dev 0.5816554427146912
patience: 5 / 6
Epoch  14  Train Loss 2.8817 99.91%
Epoch  14:  Dev 0.5748116374015808
patience: 6 / 6
setting train exemplar for learned classes
torch.Size([660, 2048])
BEST DEV 4: 0.6062052249908447
BEST TEST 4: 0.5968660712242126
