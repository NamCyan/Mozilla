Dump name space
results/ace/ExcessMTL_woLMH_woSR_woSAM_woLosstrick_narate-40_cluster-8_gen-10_robust_step_size-0.0001/perm_2/options.json
Dump name space
results/ace/ExcessMTL_woLMH_woSR_woSAM_woLosstrick_narate-40_cluster-8_gen-10_robust_step_size-0.0001/perm_2/options.json
Dump name space
results/ace/ExcessMTL_woLMH_woSR_woSAM_woLosstrick_narate-40_cluster-8_gen-10_robust_step_size-0.0001/perm_2/options.json
Dump name space
results/ace/ExcessMTL_woLMH_woSR_woSAM_woLosstrick_narate-40_cluster-8_gen-10_robust_step_size-0.0001/perm_2/options.json
Dump name space
results/ace/ExcessMTL_woLMH_woSR_woSAM_woLosstrick_narate-40_cluster-8_gen-10_robust_step_size-0.0001/perm_2/options.json
[[188, 199, 184, 194, 189, 190, 178, 186, 197, 0], [200, 180, 173, 198, 177, 0], [191, 187, 195, 171, 174, 179, 0], [196, 181, 182, 202, 185, 176, 170, 192, 0], [201, 183, 193, 172, 175, 0]]
False
train loader and exclude loader:  0
Original len train instances: 265115
train loader and exclude loader:  1
Original len train instances: 264531
train loader and exclude loader:  2
Original len train instances: 263812
train loader and exclude loader:  3
Original len train instances: 262973
train loader and exclude loader:  4
Original len train instances: 262361
Original len dev instances: 54053
Original len test instances: 93949
create basgMTL 4
False False
Epoch   1  Train Loss 0.0569 98.17%
Epoch   1:  Dev 0.5583756566047668
Epoch   1: Test 0.4892086088657379
patience: 0 / 6
Epoch   2  Train Loss 0.0054 98.55%
Epoch   2:  Dev 0.610837459564209
Epoch   2: Test 0.5616438388824463
patience: 0 / 6
Epoch   3  Train Loss 0.0042 98.56%
Epoch   3:  Dev 0.5929203629493713
patience: 1 / 6
Epoch   4  Train Loss 0.0034 98.58%
Epoch   4:  Dev 0.610837459564209
patience: 2 / 6
Epoch   5  Train Loss 0.0029 98.59%
Epoch   5:  Dev 0.5999999642372131
patience: 3 / 6
Epoch   6  Train Loss 0.0023 98.60%
Epoch   6:  Dev 0.6371681690216064
Epoch   6: Test 0.5641025304794312
patience: 0 / 6
Epoch   7  Train Loss 0.0019 98.61%
Epoch   7:  Dev 0.607003927230835
patience: 1 / 6
Epoch   8  Train Loss 0.0016 98.63%
Epoch   8:  Dev 0.5923076868057251
patience: 2 / 6
Epoch   9  Train Loss 0.0013 98.63%
Epoch   9:  Dev 0.5984252095222473
patience: 3 / 6
Epoch  10  Train Loss 0.0012 98.63%
Epoch  10:  Dev 0.6190476417541504
patience: 4 / 6
Epoch  11  Train Loss 0.0011 98.64%
Epoch  11:  Dev 0.6037735939025879
patience: 5 / 6
Epoch  12  Train Loss 0.0010 98.64%
Epoch  12:  Dev 0.581818163394928
patience: 6 / 6
setting train exemplar for learned classes
torch.Size([180, 2048])
BEST DEV 0: 0.6371681690216064
BEST TEST 0: 0.5641025304794312
torch.Size([180, 2048])
Epoch   1  Train Loss 3.0169 99.48%
Epoch   1:  Dev 0.4677804112434387
Epoch   1: Test 0.5257142782211304
patience: 0 / 6
Epoch   2  Train Loss 3.3249 99.75%
Epoch   2:  Dev 0.5213483572006226
Epoch   2: Test 0.5610389709472656
patience: 0 / 6
Epoch   3  Train Loss 3.4793 99.79%
Epoch   3:  Dev 0.5785877108573914
Epoch   3: Test 0.557640790939331
patience: 0 / 6
Epoch   4  Train Loss 3.1559 99.83%
Epoch   4:  Dev 0.5882352590560913
Epoch   4: Test 0.5504087209701538
patience: 0 / 6
Epoch   5  Train Loss 0.2072 99.83%
Epoch   5:  Dev 0.49079760909080505
patience: 1 / 6
Epoch   6  Train Loss 3.4429 99.88%
Epoch   6:  Dev 0.5922551155090332
Epoch   6: Test 0.5790754556655884
patience: 0 / 6
Epoch   7  Train Loss 3.4020 99.91%
Epoch   7:  Dev 0.5787037014961243
patience: 1 / 6
Epoch   8  Train Loss 3.2857 99.91%
Epoch   8:  Dev 0.56611567735672
patience: 2 / 6
Epoch   9  Train Loss 3.5051 99.92%
Epoch   9:  Dev 0.5949656367301941
Epoch   9: Test 0.5472155213356018
patience: 0 / 6
Epoch  10  Train Loss 3.2404 99.93%
Epoch  10:  Dev 0.582524299621582
patience: 1 / 6
Epoch  11  Train Loss 3.4995 99.95%
Epoch  11:  Dev 0.5613305568695068
patience: 2 / 6
Epoch  12  Train Loss 3.1412 99.96%
Epoch  12:  Dev 0.5800464153289795
patience: 3 / 6
Epoch  13  Train Loss 3.1794 99.96%
Epoch  13:  Dev 0.5781990885734558
patience: 4 / 6
Epoch  14  Train Loss 2.8810 99.96%
Epoch  14:  Dev 0.5912240147590637
patience: 5 / 6
Epoch  15  Train Loss 3.2185 99.96%
Epoch  15:  Dev 0.570155918598175
patience: 6 / 6
setting train exemplar for learned classes
torch.Size([280, 2048])
BEST DEV 1: 0.5949656367301941
BEST TEST 1: 0.5472155213356018
torch.Size([280, 2048])
Epoch   1  Train Loss 2.3840 99.22%
Epoch   1:  Dev 0.5776031613349915
Epoch   1: Test 0.5751634240150452
patience: 0 / 6
Epoch   2  Train Loss 1.5476 99.81%
Epoch   2:  Dev 0.5689278244972229
patience: 1 / 6
Epoch   3  Train Loss 2.1369 99.84%
Epoch   3:  Dev 0.5795207619667053
Epoch   3: Test 0.5665529370307922
patience: 0 / 6
Epoch   4  Train Loss 2.5869 99.86%
Epoch   4:  Dev 0.5925925970077515
Epoch   4: Test 0.6076335310935974
patience: 0 / 6
Epoch   5  Train Loss 2.5601 99.87%
Epoch   5:  Dev 0.6003898978233337
Epoch   5: Test 0.5928143262863159
patience: 0 / 6
Epoch   6  Train Loss 2.4597 99.88%
Epoch   6:  Dev 0.5818182229995728
patience: 1 / 6
Epoch   7  Train Loss 2.4046 99.89%
Epoch   7:  Dev 0.5918368101119995
patience: 2 / 6
Epoch   8  Train Loss 2.5337 99.91%
Epoch   8:  Dev 0.5928853750228882
patience: 3 / 6
Epoch   9  Train Loss 2.1520 99.91%
Epoch   9:  Dev 0.5689655542373657
patience: 4 / 6
Epoch  10  Train Loss 2.5903 99.93%
Epoch  10:  Dev 0.5931863784790039
patience: 5 / 6
Epoch  11  Train Loss 2.5937 99.94%
Epoch  11:  Dev 0.6048387289047241
Epoch  11: Test 0.5925926566123962
patience: 0 / 6
Epoch  12  Train Loss 2.3585 99.94%
Epoch  12:  Dev 0.5822784900665283
patience: 1 / 6
Epoch  13  Train Loss 2.4918 99.95%
Epoch  13:  Dev 0.5865581035614014
patience: 2 / 6
Epoch  14  Train Loss 2.5611 99.95%
Epoch  14:  Dev 0.5889570116996765
patience: 3 / 6
Epoch  15  Train Loss 0.4017 99.93%
Epoch  15:  Dev 0.43352600932121277
patience: 4 / 6
Epoch  16  Train Loss 0.1065 99.95%
Epoch  16:  Dev 0.43874645233154297
patience: 5 / 6
Epoch  17  Train Loss 2.6407 99.97%
Epoch  17:  Dev 0.5696202516555786
patience: 6 / 6
setting train exemplar for learned classes
torch.Size([400, 2048])
BEST DEV 2: 0.6048387289047241
BEST TEST 2: 0.5925926566123962
torch.Size([400, 2048])
