Dump name space
results/ace/ExcessMTL_woLMH_woSR_woSAM_woLosstrick_narate-40_cluster-8_gen-10_robust_step_size-0.001/perm_3/options.json
Dump name space
results/ace/ExcessMTL_woLMH_woSR_woSAM_woLosstrick_narate-40_cluster-8_gen-10_robust_step_size-0.001/perm_3/options.json
Dump name space
results/ace/ExcessMTL_woLMH_woSR_woSAM_woLosstrick_narate-40_cluster-8_gen-10_robust_step_size-0.001/perm_3/options.json
Dump name space
results/ace/ExcessMTL_woLMH_woSR_woSAM_woLosstrick_narate-40_cluster-8_gen-10_robust_step_size-0.001/perm_3/options.json
Dump name space
results/ace/ExcessMTL_woLMH_woSR_woSAM_woLosstrick_narate-40_cluster-8_gen-10_robust_step_size-0.001/perm_3/options.json
[[191, 187, 195, 171, 174, 179, 0], [201, 183, 193, 172, 175, 0], [188, 199, 184, 194, 189, 190, 178, 186, 197, 0], [200, 180, 173, 198, 177, 0], [196, 181, 182, 202, 185, 176, 170, 192, 0]]
False
train loader and exclude loader:  0
Original len train instances: 265115
train loader and exclude loader:  1
Original len train instances: 264276
train loader and exclude loader:  2
Original len train instances: 262942
train loader and exclude loader:  3
Original len train instances: 262358
train loader and exclude loader:  4
Original len train instances: 261639
Original len dev instances: 54053
Original len test instances: 93949
create basgMTL 4
False False
Epoch   1  Train Loss 0.0482 98.28%
Epoch   1:  Dev 0.5373134613037109
Epoch   1: Test 0.6693547964096069
patience: 0 / 6
Epoch   2  Train Loss 0.0065 98.61%
Epoch   2:  Dev 0.6285714507102966
Epoch   2: Test 0.6666666865348816
patience: 0 / 6
Epoch   3  Train Loss 0.0053 98.63%
Epoch   3:  Dev 0.6133332848548889
patience: 1 / 6
Epoch   4  Train Loss 0.0044 98.65%
Epoch   4:  Dev 0.5588235259056091
patience: 2 / 6
Epoch   5  Train Loss 0.0037 98.66%
Epoch   5:  Dev 0.5925925374031067
patience: 3 / 6
Epoch   6  Train Loss 0.0031 98.67%
Epoch   6:  Dev 0.6233766078948975
patience: 4 / 6
Epoch   7  Train Loss 0.0025 98.69%
Epoch   7:  Dev 0.6352941393852234
Epoch   7: Test 0.6523297429084778
patience: 0 / 6
Epoch   8  Train Loss 0.0021 98.71%
Epoch   8:  Dev 0.6363636255264282
Epoch   8: Test 0.6643357276916504
patience: 0 / 6
Epoch   9  Train Loss 0.0017 98.72%
Epoch   9:  Dev 0.5897435545921326
patience: 1 / 6
Epoch  10  Train Loss 0.0016 98.72%
Epoch  10:  Dev 0.6153846383094788
patience: 2 / 6
Epoch  11  Train Loss 0.0014 98.73%
Epoch  11:  Dev 0.6075949668884277
patience: 3 / 6
Epoch  12  Train Loss 0.0011 98.74%
Epoch  12:  Dev 0.5974025726318359
patience: 4 / 6
Epoch  13  Train Loss 0.0010 98.74%
Epoch  13:  Dev 0.6233766078948975
patience: 5 / 6
Epoch  14  Train Loss 0.0011 98.74%
Epoch  14:  Dev 0.6136364340782166
patience: 6 / 6
setting train exemplar for learned classes
torch.Size([120, 2048])
BEST DEV 0: 0.6363636255264282
BEST TEST 0: 0.6643357276916504
torch.Size([120, 2048])
Epoch   1  Train Loss 1.0640 99.36%
Epoch   1:  Dev 0.6438356041908264
Epoch   1: Test 0.6741854548454285
patience: 0 / 6
Epoch   2  Train Loss 0.5812 99.70%
Epoch   2:  Dev 0.6551724076271057
Epoch   2: Test 0.6900878548622131
patience: 0 / 6
Epoch   3  Train Loss 2.4062 99.71%
Epoch   3:  Dev 0.6833855509757996
Epoch   3: Test 0.7236534357070923
patience: 0 / 6
Epoch   4  Train Loss 1.9614 99.76%
Epoch   4:  Dev 0.6835443377494812
Epoch   4: Test 0.7266187071800232
patience: 0 / 6
Epoch   5  Train Loss 1.1467 99.80%
Epoch   5:  Dev 0.6774193644523621
patience: 1 / 6
Epoch   6  Train Loss 0.1752 99.81%
Epoch   6:  Dev 0.6851851344108582
Epoch   6: Test 0.7314815521240234
patience: 0 / 6
Epoch   7  Train Loss 2.0764 99.82%
Epoch   7:  Dev 0.6796116232872009
patience: 1 / 6
Epoch   8  Train Loss 2.3865 99.83%
Epoch   8:  Dev 0.6884272694587708
Epoch   8: Test 0.7082860469818115
patience: 0 / 6
Epoch   9  Train Loss 0.5097 99.88%
Epoch   9:  Dev 0.6791277527809143
patience: 1 / 6
Epoch  10  Train Loss 1.5927 99.88%
Epoch  10:  Dev 0.6686567664146423
patience: 2 / 6
Epoch  11  Train Loss 2.7029 99.87%
Epoch  11:  Dev 0.6976744532585144
Epoch  11: Test 0.7045707702636719
patience: 0 / 6
Epoch  12  Train Loss 1.2285 99.91%
Epoch  12:  Dev 0.6687116622924805
patience: 1 / 6
Epoch  13  Train Loss 0.3674 99.90%
Epoch  13:  Dev 0.6925373673439026
patience: 2 / 6
Epoch  14  Train Loss 0.0536 99.87%
Epoch  14:  Dev 0.5830258131027222
patience: 3 / 6
Epoch  15  Train Loss 0.7668 99.92%
Epoch  15:  Dev 0.6811145544052124
patience: 4 / 6
Epoch  16  Train Loss 3.3103 99.95%
Epoch  16:  Dev 0.6850153207778931
patience: 5 / 6
Epoch  17  Train Loss 0.7632 99.95%
Epoch  17:  Dev 0.6896551847457886
patience: 6 / 6
setting train exemplar for learned classes
torch.Size([220, 2048])
BEST DEV 1: 0.6976744532585144
BEST TEST 1: 0.7045707702636719
torch.Size([220, 2048])
Epoch   1  Train Loss 1.9594 99.19%
Epoch   1:  Dev 0.6350515484809875
Epoch   1: Test 0.6759656667709351
patience: 0 / 6
Epoch   2  Train Loss 2.5768 99.80%
Epoch   2:  Dev 0.6691728830337524
Epoch   2: Test 0.6937119364738464
patience: 0 / 6
Epoch   3  Train Loss 2.2633 99.84%
Epoch   3:  Dev 0.650646984577179
patience: 1 / 6
Epoch   4  Train Loss 2.6914 99.85%
Epoch   4:  Dev 0.6520146131515503
patience: 2 / 6
Epoch   5  Train Loss 1.9013 99.86%
Epoch   5:  Dev 0.6604823470115662
patience: 3 / 6
Epoch   6  Train Loss 0.9707 99.85%
Epoch   6:  Dev 0.6520146131515503
patience: 4 / 6
Epoch   7  Train Loss 0.2718 99.87%
Epoch   7:  Dev 0.5059102177619934
patience: 5 / 6
Epoch   8  Train Loss 0.0385 99.91%
Epoch   8:  Dev 0.42505592107772827
patience: 6 / 6
setting train exemplar for learned classes
torch.Size([400, 2048])
BEST DEV 2: 0.6691728830337524
BEST TEST 2: 0.6937119364738464
torch.Size([400, 2048])
Epoch   1  Train Loss 1.0195 99.14%
Epoch   1:  Dev 0.5893129706382751
Epoch   1: Test 0.6599817872047424
patience: 0 / 6
Epoch   2  Train Loss 2.3512 99.65%
Epoch   2:  Dev 0.6351351141929626
Epoch   2: Test 0.6602787971496582
patience: 0 / 6
Epoch   3  Train Loss 2.6068 99.73%
Epoch   3:  Dev 0.6460295915603638
Epoch   3: Test 0.6573181748390198
patience: 0 / 6
Epoch   4  Train Loss 2.2418 99.77%
Epoch   4:  Dev 0.6541555523872375
Epoch   4: Test 0.6727727055549622
patience: 0 / 6
Epoch   5  Train Loss 2.4430 99.80%
Epoch   5:  Dev 0.6611797213554382
Epoch   5: Test 0.6702128052711487
patience: 0 / 6
Epoch   6  Train Loss 1.9008 99.81%
Epoch   6:  Dev 0.6547455191612244
patience: 1 / 6
Epoch   7  Train Loss 1.2931 99.84%
Epoch   7:  Dev 0.6684492230415344
Epoch   7: Test 0.6855241060256958
patience: 0 / 6
Epoch   8  Train Loss 0.4997 99.84%
Epoch   8:  Dev 0.5580589175224304
patience: 1 / 6
Epoch   9  Train Loss 2.3248 99.90%
Epoch   9:  Dev 0.6417704224586487
patience: 2 / 6
Epoch  10  Train Loss 2.5666 99.92%
Epoch  10:  Dev 0.631147563457489
patience: 3 / 6
Epoch  11  Train Loss 1.7941 99.92%
Epoch  11:  Dev 0.6466380953788757
patience: 4 / 6
Epoch  12  Train Loss 0.7531 99.93%
Epoch  12:  Dev 0.5199307203292847
patience: 5 / 6
Epoch  13  Train Loss 1.8035 99.96%
Epoch  13:  Dev 0.6288343667984009
patience: 6 / 6
setting train exemplar for learned classes
torch.Size([500, 2048])
BEST DEV 3: 0.6684492230415344
BEST TEST 3: 0.6855241060256958
torch.Size([500, 2048])
Epoch   1  Train Loss 1.3836 98.82%
Epoch   1:  Dev 0.6070991158485413
Epoch   1: Test 0.6035767793655396
patience: 0 / 6
Epoch   2  Train Loss 3.3457 99.70%
Epoch   2:  Dev 0.6373901963233948
Epoch   2: Test 0.5744336843490601
patience: 0 / 6
Epoch   3  Train Loss 2.2172 99.75%
Epoch   3:  Dev 0.6565774083137512
Epoch   3: Test 0.6314243674278259
patience: 0 / 6
Epoch   4  Train Loss 2.2240 99.80%
Epoch   4:  Dev 0.6375321745872498
patience: 1 / 6
Epoch   5  Train Loss 2.3341 99.83%
Epoch   5:  Dev 0.6516052484512329
patience: 2 / 6
Epoch   6  Train Loss 2.9903 99.85%
Epoch   6:  Dev 0.6368159055709839
patience: 3 / 6
Epoch   7  Train Loss 2.7029 99.88%
Epoch   7:  Dev 0.636033833026886
patience: 4 / 6
Epoch   8  Train Loss 3.1051 99.90%
Epoch   8:  Dev 0.6344485282897949
patience: 5 / 6
Epoch   9  Train Loss 1.5445 99.91%
Epoch   9:  Dev 0.5839018225669861
patience: 6 / 6
setting train exemplar for learned classes
torch.Size([660, 2048])
BEST DEV 4: 0.6565774083137512
BEST TEST 4: 0.6314243674278259
