Dump name space
results/ace/ExcessMTL_woLMH_woSR_woSAM_woLosstrick_narate-40_cluster-8_gen-10_robust_step_size-0.001/perm_0/options.json
Dump name space
results/ace/ExcessMTL_woLMH_woSR_woSAM_woLosstrick_narate-40_cluster-8_gen-10_robust_step_size-0.001/perm_0/options.json
Dump name space
results/ace/ExcessMTL_woLMH_woSR_woSAM_woLosstrick_narate-40_cluster-8_gen-10_robust_step_size-0.001/perm_0/options.json
Dump name space
results/ace/ExcessMTL_woLMH_woSR_woSAM_woLosstrick_narate-40_cluster-8_gen-10_robust_step_size-0.001/perm_0/options.json
Dump name space
results/ace/ExcessMTL_woLMH_woSR_woSAM_woLosstrick_narate-40_cluster-8_gen-10_robust_step_size-0.001/perm_0/options.json
[[188, 199, 184, 194, 189, 190, 178, 186, 197, 0], [191, 187, 195, 171, 174, 179, 0], [201, 183, 193, 172, 175, 0], [200, 180, 173, 198, 177, 0], [196, 181, 182, 202, 185, 176, 170, 192, 0]]
False
train loader and exclude loader:  0
Original len train instances: 265115
train loader and exclude loader:  1
Original len train instances: 264531
train loader and exclude loader:  2
Original len train instances: 263692
train loader and exclude loader:  3
Original len train instances: 262358
train loader and exclude loader:  4
Original len train instances: 261639
Original len dev instances: 54053
Original len test instances: 93949
create basgMTL 4
False False
Epoch   1  Train Loss 0.0569 98.17%
Epoch   1:  Dev 0.5670103430747986
Epoch   1: Test 0.48175179958343506
patience: 0 / 6
Epoch   2  Train Loss 0.0054 98.55%
Epoch   2:  Dev 0.610837459564209
Epoch   2: Test 0.5810810923576355
patience: 0 / 6
Epoch   3  Train Loss 0.0042 98.56%
Epoch   3:  Dev 0.5991189479827881
patience: 1 / 6
Epoch   4  Train Loss 0.0034 98.58%
Epoch   4:  Dev 0.6336633563041687
Epoch   4: Test 0.442748099565506
patience: 0 / 6
Epoch   5  Train Loss 0.0029 98.59%
Epoch   5:  Dev 0.6265060305595398
patience: 1 / 6
Epoch   6  Train Loss 0.0023 98.60%
Epoch   6:  Dev 0.6406926512718201
Epoch   6: Test 0.5584415793418884
patience: 0 / 6
Epoch   7  Train Loss 0.0019 98.61%
Epoch   7:  Dev 0.604651153087616
patience: 1 / 6
Epoch   8  Train Loss 0.0016 98.62%
Epoch   8:  Dev 0.5855513215065002
patience: 2 / 6
Epoch   9  Train Loss 0.0013 98.63%
Epoch   9:  Dev 0.5846154093742371
patience: 3 / 6
Epoch  10  Train Loss 0.0012 98.63%
Epoch  10:  Dev 0.5877861976623535
patience: 4 / 6
Epoch  11  Train Loss 0.0011 98.64%
Epoch  11:  Dev 0.5984848737716675
patience: 5 / 6
Epoch  12  Train Loss 0.0010 98.64%
Epoch  12:  Dev 0.597014844417572
patience: 6 / 6
setting train exemplar for learned classes
torch.Size([180, 2048])
BEST DEV 0: 0.6406926512718201
BEST TEST 0: 0.5584415793418884
torch.Size([180, 2048])
Epoch   1  Train Loss 0.2500 99.53%
Epoch   1:  Dev 0.5390070676803589
Epoch   1: Test 0.3576158881187439
patience: 0 / 6
Epoch   2  Train Loss 0.2627 99.65%
Epoch   2:  Dev 0.5422535538673401
Epoch   2: Test 0.3445945978164673
patience: 0 / 6
Epoch   3  Train Loss 0.3125 99.72%
Epoch   3:  Dev 0.5667752623558044
Epoch   3: Test 0.5530726313591003
patience: 0 / 6
Epoch   4  Train Loss 0.2724 99.74%
Epoch   4:  Dev 0.5910652875900269
Epoch   4: Test 0.5659340620040894
patience: 0 / 6
Epoch   5  Train Loss 0.2773 99.79%
Epoch   5:  Dev 0.6456140279769897
Epoch   5: Test 0.6368159055709839
patience: 0 / 6
Epoch   6  Train Loss 0.3935 99.83%
Epoch   6:  Dev 0.6134969592094421
patience: 1 / 6
Epoch   7  Train Loss 0.5638 99.83%
Epoch   7:  Dev 0.6309148073196411
patience: 2 / 6
Epoch   8  Train Loss 0.5730 99.84%
Epoch   8:  Dev 0.6089552044868469
patience: 3 / 6
Epoch   9  Train Loss 3.4721 99.83%
Epoch   9:  Dev 0.5947521924972534
patience: 4 / 6
Epoch  10  Train Loss 0.9905 99.86%
Epoch  10:  Dev 0.6200607419013977
patience: 5 / 6
Epoch  11  Train Loss 3.4247 99.85%
Epoch  11:  Dev 0.5958702564239502
patience: 6 / 6
setting train exemplar for learned classes
torch.Size([300, 2048])
BEST DEV 1: 0.6456140279769897
BEST TEST 1: 0.6368159055709839
torch.Size([300, 2048])
Epoch   1  Train Loss 0.6786 98.95%
Epoch   1:  Dev 0.47432762384414673
Epoch   1: Test 0.36209335923194885
patience: 0 / 6
Epoch   2  Train Loss 1.2046 99.59%
Epoch   2:  Dev 0.6573705077171326
Epoch   2: Test 0.6732456088066101
patience: 0 / 6
Epoch   3  Train Loss 1.5578 99.67%
Epoch   3:  Dev 0.6912620663642883
Epoch   3: Test 0.707027018070221
patience: 0 / 6
Epoch   4  Train Loss 0.2519 99.74%
Epoch   4:  Dev 0.5482233762741089
patience: 1 / 6
Epoch   5  Train Loss 2.9771 99.78%
Epoch   5:  Dev 0.6775362491607666
patience: 2 / 6
Epoch   6  Train Loss 1.9863 99.80%
Epoch   6:  Dev 0.6728624701499939
patience: 3 / 6
Epoch   7  Train Loss 2.9905 99.81%
Epoch   7:  Dev 0.6726619005203247
patience: 4 / 6
Epoch   8  Train Loss 1.4191 99.83%
Epoch   8:  Dev 0.6830188632011414
patience: 5 / 6
Epoch   9  Train Loss 0.9630 99.81%
Epoch   9:  Dev 0.6641075015068054
patience: 6 / 6
setting train exemplar for learned classes
torch.Size([400, 2048])
BEST DEV 2: 0.6912620663642883
BEST TEST 2: 0.707027018070221
torch.Size([400, 2048])
Epoch   1  Train Loss 1.3094 99.08%
Epoch   1:  Dev 0.6022544503211975
Epoch   1: Test 0.6456542611122131
patience: 0 / 6
Epoch   2  Train Loss 2.9135 99.64%
Epoch   2:  Dev 0.6374268531799316
Epoch   2: Test 0.6690203547477722
patience: 0 / 6
Epoch   3  Train Loss 3.2362 99.71%
Epoch   3:  Dev 0.6501457691192627
Epoch   3: Test 0.6512866020202637
patience: 0 / 6
Epoch   4  Train Loss 2.6249 99.75%
Epoch   4:  Dev 0.676176905632019
Epoch   4: Test 0.671256422996521
patience: 0 / 6
Epoch   5  Train Loss 1.9789 99.75%
Epoch   5:  Dev 0.665693461894989
patience: 1 / 6
Epoch   6  Train Loss 2.7670 99.77%
Epoch   6:  Dev 0.669552743434906
patience: 2 / 6
Epoch   7  Train Loss 1.6539 99.79%
Epoch   7:  Dev 0.6694915890693665
patience: 3 / 6
Epoch   8  Train Loss 0.8675 99.82%
Epoch   8:  Dev 0.6066666841506958
patience: 4 / 6
Epoch   9  Train Loss 2.3661 99.87%
Epoch   9:  Dev 0.64371258020401
patience: 5 / 6
Epoch  10  Train Loss 1.4685 99.89%
Epoch  10:  Dev 0.5764330625534058
patience: 6 / 6
setting train exemplar for learned classes
torch.Size([500, 2048])
BEST DEV 3: 0.676176905632019
BEST TEST 3: 0.671256422996521
torch.Size([500, 2048])
Epoch   1  Train Loss 1.4864 97.29%
Epoch   1:  Dev 0.5955203771591187
Epoch   1: Test 0.604615330696106
patience: 0 / 6
Epoch   2  Train Loss 2.7833 99.61%
Epoch   2:  Dev 0.5891277194023132
patience: 1 / 6
Epoch   3  Train Loss 2.3686 99.67%
Epoch   3:  Dev 0.6271604895591736
Epoch   3: Test 0.6065574288368225
patience: 0 / 6
Epoch   4  Train Loss 2.4281 99.71%
Epoch   4:  Dev 0.6478527784347534
Epoch   4: Test 0.6128550171852112
patience: 0 / 6
Epoch   5  Train Loss 2.6857 99.76%
Epoch   5:  Dev 0.6327826976776123
patience: 1 / 6
Epoch   6  Train Loss 2.5477 99.77%
Epoch   6:  Dev 0.6400996446609497
patience: 2 / 6
Epoch   7  Train Loss 3.6621 99.82%
Epoch   7:  Dev 0.6240409016609192
patience: 3 / 6
Epoch   8  Train Loss 3.3031 99.83%
Epoch   8:  Dev 0.6381909847259521
patience: 4 / 6
Epoch   9  Train Loss 2.6196 99.83%
Epoch   9:  Dev 0.6422250270843506
patience: 5 / 6
Epoch  10  Train Loss 2.2050 99.87%
Epoch  10:  Dev 0.5718390941619873
patience: 6 / 6
setting train exemplar for learned classes
torch.Size([660, 2048])
BEST DEV 4: 0.6478527784347534
BEST TEST 4: 0.6128550171852112
