Dump name space
results/maven/ExcessMTL_woLMH_woSR_woSAM_woLosstrick_narate-4_cluster-4_gen-20_robust_step_size-0.001/perm_2/options.json
Dump name space
results/maven/ExcessMTL_woLMH_woSR_woSAM_woLosstrick_narate-4_cluster-4_gen-20_robust_step_size-0.001/perm_2/options.json
Dump name space
results/maven/ExcessMTL_woLMH_woSR_woSAM_woLosstrick_narate-4_cluster-4_gen-20_robust_step_size-0.001/perm_2/options.json
Dump name space
results/maven/ExcessMTL_woLMH_woSR_woSAM_woLosstrick_narate-4_cluster-4_gen-20_robust_step_size-0.001/perm_2/options.json
Dump name space
results/maven/ExcessMTL_woLMH_woSR_woSAM_woLosstrick_narate-4_cluster-4_gen-20_robust_step_size-0.001/perm_2/options.json
[[134, 99, 105, 91, 52, 19, 135, 122, 127, 102, 108, 104, 110, 38, 118, 121, 160, 26, 34, 33, 158, 130, 165, 86, 149, 146, 164, 4, 131, 75, 90, 10, 32, 0], [157, 18, 114, 92, 67, 153, 80, 115, 78, 154, 27, 5, 69, 117, 44, 83, 155, 40, 45, 139, 137, 14, 138, 119, 74, 150, 59, 54, 28, 9, 140, 37, 107, 76, 47, 0], [46, 36, 17, 13, 12, 20, 25, 49, 169, 148, 87, 56, 95, 81, 58, 57, 161, 64, 163, 82, 43, 125, 35, 96, 156, 100, 66, 30, 50, 120, 0], [151, 16, 3, 70, 106, 141, 68, 31, 79, 101, 166, 167, 94, 21, 51, 7, 73, 145, 2, 124, 159, 61, 41, 142, 126, 144, 55, 168, 29, 11, 24, 0], [147, 48, 84, 39, 53, 23, 109, 22, 77, 62, 93, 143, 89, 8, 71, 85, 63, 97, 65, 103, 113, 112, 123, 152, 88, 98, 72, 42, 60, 133, 128, 116, 15, 111, 136, 162, 129, 132, 6, 0]]
True
train loader and exclude loader:  0
Original len train instances: 347788
train loader and exclude loader:  1
Original len train instances: 334861
train loader and exclude loader:  2
Original len train instances: 321448
train loader and exclude loader:  3
Original len train instances: 309156
train loader and exclude loader:  4
Original len train instances: 294589
Original len dev instances: 57198
Original len test instances: 98603
create basgMTL 4
False False
Epoch   1  Train Loss 0.1507 81.25%
Epoch   1:  Dev 0.5277435183525085
Epoch   1: Test 0.5487741231918335
patience: 0 / 5
Epoch   2  Train Loss 0.0748 82.09%
Epoch   2:  Dev 0.6476141810417175
Epoch   2: Test 0.6559699177742004
patience: 0 / 5
Epoch   3  Train Loss 0.0656 82.24%
Epoch   3:  Dev 0.6041265726089478
patience: 1 / 5
Epoch   4  Train Loss 0.0593 82.34%
Epoch   4:  Dev 0.6396372318267822
patience: 2 / 5
Epoch   5  Train Loss 0.0544 82.45%
Epoch   5:  Dev 0.6557628512382507
Epoch   5: Test 0.6637630462646484
patience: 0 / 5
Epoch   6  Train Loss 0.0499 82.53%
Epoch   6:  Dev 0.6346749067306519
patience: 1 / 5
Epoch   7  Train Loss 0.0457 82.67%
Epoch   7:  Dev 0.6642084717750549
Epoch   7: Test 0.6746651530265808
patience: 0 / 5
Epoch   8  Train Loss 0.0419 82.77%
Epoch   8:  Dev 0.6607494950294495
patience: 1 / 5
Epoch   9  Train Loss 0.0388 82.83%
Epoch   9:  Dev 0.6621553897857666
patience: 2 / 5
Epoch  10  Train Loss 0.0352 82.96%
Epoch  10:  Dev 0.6330517530441284
patience: 3 / 5
Epoch  11  Train Loss 0.0324 83.06%
Epoch  11:  Dev 0.6655112504959106
Epoch  11: Test 0.6773969531059265
patience: 0 / 5
Epoch  12  Train Loss 0.0298 83.13%
Epoch  12:  Dev 0.630122721195221
patience: 1 / 5
Epoch  13  Train Loss 0.0274 83.22%
Epoch  13:  Dev 0.6651895642280579
patience: 2 / 5
Epoch  14  Train Loss 0.0257 83.29%
Epoch  14:  Dev 0.646335244178772
patience: 3 / 5
Epoch  15  Train Loss 0.0241 83.32%
Epoch  15:  Dev 0.6676089763641357
Epoch  15: Test 0.6721638441085815
patience: 0 / 5
setting train exemplar for learned classes
torch.Size([660, 2048])
BEST DEV 0: 0.6676089763641357
BEST TEST 0: 0.6721638441085815
torch.Size([660, 2048])
Epoch   1  Train Loss 2.8825 95.55%
Epoch   1:  Dev 0.5610049366950989
Epoch   1: Test 0.5660057067871094
patience: 0 / 5
Epoch   2  Train Loss 3.3333 96.33%
Epoch   2:  Dev 0.5800244212150574
Epoch   2: Test 0.5855938792228699
patience: 0 / 5
Epoch   3  Train Loss 4.4886 96.66%
Epoch   3:  Dev 0.5837522745132446
Epoch   3: Test 0.5937524437904358
patience: 0 / 5
Epoch   4  Train Loss 5.1227 97.04%
Epoch   4:  Dev 0.5792558193206787
patience: 1 / 5
Epoch   5  Train Loss 5.2481 97.25%
Epoch   5:  Dev 0.5856080055236816
Epoch   5: Test 0.5828922986984253
patience: 0 / 5
Epoch   6  Train Loss 4.8727 97.35%
Epoch   6:  Dev 0.5771476030349731
patience: 1 / 5
Epoch   7  Train Loss 4.0881 97.41%
Epoch   7:  Dev 0.5881891250610352
Epoch   7: Test 0.5908953547477722
patience: 0 / 5
Epoch   8  Train Loss 5.1721 97.67%
Epoch   8:  Dev 0.559380829334259
patience: 1 / 5
Epoch   9  Train Loss 5.2022 97.85%
Epoch   9:  Dev 0.5819370746612549
patience: 2 / 5
Epoch  10  Train Loss 4.7068 97.96%
Epoch  10:  Dev 0.5762666463851929
patience: 3 / 5
Epoch  11  Train Loss 4.4230 98.02%
Epoch  11:  Dev 0.5949154496192932
Epoch  11: Test 0.5989559888839722
patience: 0 / 5
Epoch  12  Train Loss 5.0120 98.18%
Epoch  12:  Dev 0.5767991542816162
patience: 1 / 5
Epoch  13  Train Loss 4.5130 98.31%
Epoch  13:  Dev 0.5602906346321106
patience: 2 / 5
Epoch  14  Train Loss 5.2069 98.54%
Epoch  14:  Dev 0.5561147928237915
patience: 3 / 5
Epoch  15  Train Loss 4.5942 98.54%
Epoch  15:  Dev 0.5798364281654358
patience: 4 / 5
setting train exemplar for learned classes
torch.Size([1360, 2048])
BEST DEV 1: 0.5949154496192932
BEST TEST 1: 0.5989559888839722
torch.Size([1360, 2048])
Epoch   1  Train Loss 3.7758 95.93%
Epoch   1:  Dev 0.5309047698974609
Epoch   1: Test 0.536152184009552
patience: 0 / 5
Epoch   2  Train Loss 3.7833 97.15%
Epoch   2:  Dev 0.5202937126159668
patience: 1 / 5
Epoch   3  Train Loss 3.6304 97.29%
Epoch   3:  Dev 0.5571576952934265
Epoch   3: Test 0.5656751990318298
patience: 0 / 5
Epoch   4  Train Loss 3.7850 97.57%
Epoch   4:  Dev 0.5175950527191162
patience: 1 / 5
Epoch   5  Train Loss 3.6029 97.75%
Epoch   5:  Dev 0.5135605335235596
patience: 2 / 5
Epoch   6  Train Loss 3.8076 97.93%
Epoch   6:  Dev 0.5330705046653748
patience: 3 / 5
Epoch   7  Train Loss 3.5235 97.97%
Epoch   7:  Dev 0.5239229798316956
patience: 4 / 5
Epoch   8  Train Loss 3.6495 98.12%
Epoch   8:  Dev 0.5326205492019653
patience: 5 / 5
setting train exemplar for learned classes
torch.Size([1960, 2048])
BEST DEV 2: 0.5571576952934265
BEST TEST 2: 0.5656751990318298
torch.Size([1960, 2048])
Epoch   1  Train Loss 5.3260 95.32%
Epoch   1:  Dev 0.49921274185180664
Epoch   1: Test 0.5020803213119507
patience: 0 / 5
Epoch   2  Train Loss 5.0788 96.56%
Epoch   2:  Dev 0.49647387862205505
patience: 1 / 5
Epoch   3  Train Loss 5.1455 96.91%
Epoch   3:  Dev 0.5024527907371521
Epoch   3: Test 0.49662792682647705
patience: 0 / 5
Epoch   4  Train Loss 5.0898 97.06%
Epoch   4:  Dev 0.5027403235435486
Epoch   4: Test 0.5033318400382996
patience: 0 / 5
Epoch   5  Train Loss 5.1374 97.27%
Epoch   5:  Dev 0.48950839042663574
patience: 1 / 5
Epoch   6  Train Loss 5.0792 97.50%
Epoch   6:  Dev 0.4944522976875305
patience: 2 / 5
Epoch   7  Train Loss 5.0992 97.65%
Epoch   7:  Dev 0.48493438959121704
patience: 3 / 5
Epoch   8  Train Loss 4.9647 97.83%
Epoch   8:  Dev 0.4867670238018036
patience: 4 / 5
Epoch   9  Train Loss 4.9991 97.97%
Epoch   9:  Dev 0.49643614888191223
patience: 5 / 5
setting train exemplar for learned classes
torch.Size([2580, 2048])
BEST DEV 3: 0.5027403235435486
BEST TEST 3: 0.5033318400382996
torch.Size([2580, 2048])
Epoch   1  Train Loss 6.3825 94.94%
Epoch   1:  Dev 0.47062423825263977
Epoch   1: Test 0.4705757796764374
patience: 0 / 5
Epoch   2  Train Loss 6.0059 96.61%
Epoch   2:  Dev 0.4609846770763397
patience: 1 / 5
Epoch   3  Train Loss 6.1044 97.01%
Epoch   3:  Dev 0.4709194302558899
Epoch   3: Test 0.47368788719177246
patience: 0 / 5
Epoch   4  Train Loss 6.0738 97.26%
Epoch   4:  Dev 0.4566088020801544
patience: 1 / 5
Epoch   5  Train Loss 6.0721 97.45%
Epoch   5:  Dev 0.4554746150970459
patience: 2 / 5
Epoch   6  Train Loss 6.0744 97.67%
Epoch   6:  Dev 0.4443616271018982
patience: 3 / 5
Epoch   7  Train Loss 6.1374 97.81%
Epoch   7:  Dev 0.45395052433013916
patience: 4 / 5
Epoch   8  Train Loss 6.0598 97.95%
Epoch   8:  Dev 0.4415648281574249
patience: 5 / 5
setting train exemplar for learned classes
torch.Size([3360, 2048])
BEST DEV 4: 0.4709194302558899
BEST TEST 4: 0.47368788719177246
